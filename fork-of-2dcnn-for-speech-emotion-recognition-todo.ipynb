{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries\r\nimport os\r\nimport librosa\r\nimport librosa.display\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow as tf\r\nfrom matplotlib.pyplot import specgram\r\nimport pandas as pd\r\nimport glob\r\nfrom sklearn.metrics import confusion_matrix\r\n# import IPython.display as ipd  # To play sound in the notebook\r\nfrom playsound import playsound\r\n\r\nimport sys\r\nimport warnings\r\nimport cv2\r\nfrom PIL import Image\r\n\r\nimport keras\r\nfrom keras import regularizers\r\nfrom keras.preprocessing import sequence\r\n# from keras.preprocessing.sequence import pad_sequences\r\nfrom keras.models import Sequential, Model, model_from_json\r\nfrom keras.layers import Dense\r\nfrom keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\r\nfrom keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\r\nfrom keras.utils import np_utils, to_categorical\r\nfrom keras.callbacks import ModelCheckpoint\r\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\r\nfrom keras.layers import LeakyReLU, ELU\r\nfrom keras import callbacks\r\nfrom keras import optimizers\r\n\r\n# sklearn\r\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.preprocessing import LabelEncoder\r\n\r\n# Other\r\nimport librosa\r\nimport librosa.display\r\nimport json\r\nimport numpy as np\r\nimport pandas as pd\r\nimport seaborn as sns\r\nimport glob\r\nimport os\r\nimport pickle\r\n\r\n# ViT libraries\r\nimport keras_cv as kcv\r\nfrom keras_cv.models import ViTTiny16\r\nfrom keras_cv.layers import preprocessing\r\n\r\n# ignore warnings\r\nif not sys.warnoptions:\r\n    warnings.simplefilter(\"ignore\")\r\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\r\n\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_virtual_device_configuration(physical_devices[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3500)])\r\n# tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n# _________________________________________________________________________________________________\r\n\r\n# some global config\r\nGLB_READ_DATA = False\r\nGLB_DISPLAY_DATA = False\r\nGLB_USE_1D_CNN = False  # todo\r\nGLB_MODE = 5 # 1 - 1D CNN create; 2 - 1D CNN toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/oronto emotional speech set data/TESS Toronto emotional speech set data/\"\r\nRAV = \"ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\r\nSAVEE = \"surrey-audiovisual-expressed-emotion-savee/ALL/\"\r\nCREMA = \"cremad/AudioWAV/\"\r\n\r\nALL_PATH_CSV = \"Data_path.csv\"\r\nMFCC_PATH_CSV = 'Data_MFCC_path.csv'\r\n# _________________________________________________________________________________________________\r\n\r\ndef ReadData_SAVEE():\r\n    print(\"________________________________________ SAVEE read data ________________________________________\")\r\n    # Get the data location for SAVEE\r\n    dir_list = os.listdir(SAVEE)\r\n\r\n    # parse the filename to get the emotions\r\n    emotion = []\r\n    path = []\r\n    for i in dir_list:\r\n        if i[-8:-6] == '_a':\r\n            emotion.append('angry')\r\n        elif i[-8:-6] == '_d':\r\n            emotion.append('disgust')\r\n        elif i[-8:-6] == '_f':\r\n            emotion.append('fear')\r\n        elif i[-8:-6] == '_h':\r\n            emotion.append('happy')\r\n        elif i[-8:-6] == '_n':\r\n            emotion.append('neutral')\r\n        elif i[-8:-6] == 'sa':\r\n            emotion.append('sad')\r\n        elif i[-8:-6] == 'su':\r\n            emotion.append('surprise')\r\n        else:\r\n            emotion.append('male_error')\r\n        path.append(SAVEE + i)\r\n\r\n    # Now check out the label count distribution\r\n    SAVEE_df = pd.DataFrame(emotion, columns=['labels'])\r\n    SAVEE_df['source'] = 'SAVEE'\r\n    SAVEE_df = pd.concat(\r\n        [SAVEE_df, pd.DataFrame(path, columns=['path'])], axis=1)\r\n    print(SAVEE_df.labels.value_counts())\r\n    print(\"\\n\")\r\n\r\n    if GLB_DISPLAY_DATA:\r\n        # use the well known Librosa library for this task\r\n        fname = SAVEE + 'DC_f11.wav'\r\n        data, sampling_rate = librosa.load(fname)\r\n        plt.figure(figsize=(15, 5))\r\n        librosa.display.waveshow(data, sr=sampling_rate)\r\n        plt.show()\r\n        # Lets play the audio\r\n        playsound(fname)\r\n\r\n    return SAVEE_df\r\ndef ReadData_RAVDESS():\r\n    print(\"________________________________________ RAVDESS read data ________________________________________\")\r\n    dir_list = os.listdir(RAV)\r\n    dir_list.sort()\r\n\r\n    emotion = []\r\n    gender = []\r\n    path = []\r\n    for i in dir_list:\r\n        fname = os.listdir(RAV + i)\r\n        for f in fname:\r\n            part = f.split('.')[0].split('-')\r\n            emotion.append(int(part[2]))\r\n            temp = int(part[6])\r\n            if temp % 2 == 0:\r\n                temp = \"female\"\r\n            else:\r\n                temp = \"male\"\r\n            gender.append(temp)\r\n            path.append(RAV + i + '/' + f)\r\n\r\n    RAV_df = pd.DataFrame(emotion)\r\n    RAV_df = RAV_df.replace({1: 'neutral', 2: 'neutral', 3: 'happy',\r\n                            4: 'sad', 5: 'angry', 6: 'fear', 7: 'disgust', 8: 'surprise'})\r\n    RAV_df = pd.concat([pd.DataFrame(gender), RAV_df], axis=1)\r\n    RAV_df.columns = ['gender', 'emotion']\r\n    # RAV_df['labels'] = RAV_df.gender + '_' + RAV_df.emotion\r\n    RAV_df['labels'] = RAV_df.emotion # REMOVED GENDER\r\n    RAV_df['source'] = 'RAVDESS'\r\n    RAV_df = pd.concat([RAV_df, pd.DataFrame(path, columns=['path'])], axis=1)\r\n    RAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\r\n    print(RAV_df.labels.value_counts())\r\n    print(\"\\n\")\r\n\r\n    # Pick a fearful track\r\n    if GLB_DISPLAY_DATA:\r\n        fname = RAV + 'Actor_14/03-01-06-02-02-02-14.wav'\r\n        data, sampling_rate = librosa.load(fname)\r\n        plt.figure(figsize=(15, 5))\r\n        librosa.display.waveshow(data, sr=sampling_rate)\r\n        plt.show()\r\n\r\n        # Lets play the audio\r\n        # playsound(fname) # FILE NEME IS TOO LONG??? WHAT???\r\n\r\n    dir_list = os.listdir(TESS)\r\n    dir_list.sort()\r\n    print(dir_list)\r\n    print(\"\\n\")\r\n\r\n    return RAV_df\r\ndef ReadData_TESS():\r\n    print(\"________________________________________ TESS read data ________________________________________\")\r\n    dir_list = os.listdir(TESS)\r\n    dir_list.sort()\r\n    print(dir_list)\r\n\r\n    path = []\r\n    emotion = []\r\n\r\n    for i in dir_list:\r\n        fname = os.listdir(TESS + i)\r\n        for f in fname:\r\n            if i == 'OAF_angry' or i == 'YAF_angry':\r\n                emotion.append('angry')\r\n            elif i == 'OAF_disgust' or i == 'YAF_disgust':\r\n                emotion.append('disgust')\r\n            elif i == 'OAF_Fear' or i == 'YAF_fear':\r\n                emotion.append('fear')\r\n            elif i == 'OAF_happy' or i == 'YAF_happy':\r\n                emotion.append('happy')\r\n            elif i == 'OAF_neutral' or i == 'YAF_neutral':\r\n                emotion.append('neutral')\r\n            elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\r\n                emotion.append('surprise')\r\n            elif i == 'OAF_Sad' or i == 'YAF_sad':\r\n                emotion.append('sad')\r\n            else:\r\n                emotion.append('Unknown')\r\n            path.append(TESS + i + \"/\" + f)\r\n\r\n    TESS_df = pd.DataFrame(emotion, columns=['labels'])\r\n    TESS_df['source'] = 'TESS'\r\n    TESS_df = pd.concat(\r\n        [TESS_df, pd.DataFrame(path, columns=['path'])], axis=1)\r\n    print(TESS_df.labels.value_counts())\r\n    print(\"\\n\")\r\n\r\n    return TESS_df\r\ndef ReadData_CREMA():\r\n    print(\"________________________________________ CREMA read data ________________________________________\")\r\n\r\n    dir_list = os.listdir(CREMA)\r\n    dir_list.sort()\r\n    print(dir_list[0:10])\r\n\r\n    gender = []\r\n    emotion = []\r\n    path = []\r\n    female = [1002, 1003, 1004, 1006, 1007, 1008, 1009, 1010, 1012, 1013, 1018, 1020, 1021, 1024, 1025, 1028, 1029, 1030, 1037, 1043, 1046, 1047, 1049,\r\n              1052, 1053, 1054, 1055, 1056, 1058, 1060, 1061, 1063, 1072, 1073, 1074, 1075, 1076, 1078, 1079, 1082, 1084, 1089, 1091]\r\n\r\n    for i in dir_list:\r\n        part = i.split('_')\r\n        if int(part[0]) in female:\r\n            temp = 'female'\r\n        else:\r\n            temp = 'male'\r\n        gender.append(temp)\r\n        if part[2] == 'SAD' and temp == 'male':\r\n            emotion.append('sad')\r\n        elif part[2] == 'ANG' and temp == 'male':\r\n            emotion.append('angry')\r\n        elif part[2] == 'DIS' and temp == 'male':\r\n            emotion.append('disgust')\r\n        elif part[2] == 'FEA' and temp == 'male':\r\n            emotion.append('fear')\r\n        elif part[2] == 'HAP' and temp == 'male':\r\n            emotion.append('happy')\r\n        elif part[2] == 'NEU' and temp == 'male':\r\n            emotion.append('neutral')\r\n        elif part[2] == 'SAD' and temp == 'female':\r\n            emotion.append('sad')\r\n        elif part[2] == 'ANG' and temp == 'female':\r\n            emotion.append('angry')\r\n        elif part[2] == 'DIS' and temp == 'female':\r\n            emotion.append('disgust')\r\n        elif part[2] == 'FEA' and temp == 'female':\r\n            emotion.append('fear')\r\n        elif part[2] == 'HAP' and temp == 'female':\r\n            emotion.append('happy')\r\n        elif part[2] == 'NEU' and temp == 'female':\r\n            emotion.append('neutral')\r\n        else:\r\n            emotion.append('Unknown')\r\n        path.append(CREMA + i)\r\n\r\n    CREMA_df = pd.DataFrame(emotion, columns=['labels'])\r\n    CREMA_df['source'] = 'CREMA'\r\n    CREMA_df = pd.concat(\r\n        [CREMA_df, pd.DataFrame(path, columns=['path'])], axis=1)\r\n    print(CREMA_df.labels.value_counts())\r\n    print(\"\\n\")\r\n\r\n    if GLB_DISPLAY_DATA:\r\n        fname = CREMA + '1012_IEO_HAP_HI.wav'\r\n        data, sampling_rate = librosa.load(fname)\r\n        plt.figure(figsize=(15, 5))\r\n        librosa.display.waveshow(data, sr=sampling_rate)\r\n        plt.show()\r\n\r\n        # Lets play the audio\r\n        playsound(fname)\r\n\r\n    return CREMA_df\r\ndef DataframesToCsv(SAVEE_df, RAV_df, TESS_df, CREMA_df):\r\n    df_all_DB = pd.concat([SAVEE_df, RAV_df, TESS_df, CREMA_df], axis=0)\r\n    print(df_all_DB.labels.value_counts())\r\n    print(df_all_DB.head())\r\n    df_all_DB.to_csv(ALL_PATH_CSV, index=False)\r\ndef MFCC_Example():\r\n    # Source - RAVDESS; Gender - Female; Emotion - Angry\r\n    path = \"ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_08/03-01-05-02-01-01-08.wav\"\r\n    X, sample_rate = librosa.load(\r\n        path, res_type='kaiser_fast', duration=2.5, sr=22050*2, offset=0.5)\r\n    mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\r\n    # audio wave\r\n    plt.figure(figsize=(20, 15))\r\n    plt.subplot(3, 1, 1)\r\n    librosa.display.waveshow(X, sr=sample_rate)\r\n    plt.title('Audio sampled at 44100 hrz')\r\n    plt.show()\r\n    # MFCC\r\n    plt.figure(figsize=(20, 15))\r\n    plt.subplot(3, 1, 1)\r\n    librosa.display.specshow(mfcc, x_axis='time')\r\n    plt.ylabel('MFCC')\r\n    # plt.colorbar()\r\n    plt.show()\r\n    # playsound(path) # PAth ToO lOnG\r\n\r\n    # Source - RAVDESS; Gender - Male; Emotion - Angry\r\n    path = \"ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_09/03-01-05-01-01-01-09.wav\"\r\n    X, sample_rate = librosa.load(\r\n        path, res_type='kaiser_fast', duration=2.5, sr=22050*2, offset=0.5)\r\n    mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\r\n    # audio wave\r\n    plt.figure(figsize=(20, 15))\r\n    plt.subplot(3, 1, 1)\r\n    librosa.display.waveshow(X, sr=sample_rate)\r\n    plt.title('Audio sampled at 44100 hrz')\r\n    # MFCC\r\n    plt.figure(figsize=(20, 15))\r\n    plt.subplot(3, 1, 1)\r\n    librosa.display.specshow(mfcc, x_axis='time')\r\n    plt.ylabel('MFCC')\r\n    # playsound(path)\r\ndef ReadData_Path_CSV():\r\n    # lets pick up the meta-data that we got from our first part of the Kernel\r\n    ref = pd.read_csv(\"Data_path.csv\")\r\n    # print(ref.head())\r\n    return ref\r\ndef DataframeAddMFCC(ref):\r\n    # Note this takes a couple of minutes (~10 mins) as we're iterating over 4 datasets\r\n    # loop feature extraction over the entire dataset\r\n    df_all_DB = pd.DataFrame(columns=['feature'])\r\n\r\n    counter = 0\r\n    for index, path in enumerate(ref.path):\r\n        X, sample_rate = librosa.load(\r\n            path, res_type='kaiser_fast', duration=2.5, sr=44100, offset=0.5)\r\n        sample_rate = np.array(sample_rate)\r\n\r\n        # mean as the feature. Could do min and max etc as well.\r\n        mfccs = np.mean(librosa.feature.mfcc(\r\n            y=X, sr=sample_rate, n_mfcc=13), axis=0)\r\n        df_all_DB.loc[counter] = [mfccs]\r\n        counter = counter+1\r\n\r\n        if counter % 100 == 0:\r\n            print(f\"Progress(MFCC): {counter}\", end=\"\\r\")\r\n\r\n    # Check a few records to make sure its processed successfully\r\n    print(len(df_all_DB))\r\n    df_all_DB.head()\r\n\r\n    # Now extract the mean bands to its own feature columns\r\n    df_all_DB = pd.concat(\r\n        [ref, pd.DataFrame(df_all_DB['feature'].values.tolist())], axis=1)\r\n\r\n    # replace NA with 0\r\n    df_all_DB = df_all_DB.fillna(0)\r\n    print(df_all_DB.shape)\r\n    print(df_all_DB[:5])\r\n\r\n    df_all_DB.to_csv(MFCC_PATH_CSV, index=False)\r\n\r\n    return df_all_DB\r\ndef PrepareData(df_all_DB):\r\n    # Split between train and test\r\n    df_split = df_all_DB\r\n    X_train, X_test, y_train, y_test = train_test_split(df_split.drop(\r\n        ['path', 'labels', 'source'], axis=1), df_split.labels, test_size=0.25, shuffle=True, random_state=4)\r\n    # Lets see how the data present itself before normalisation\r\n    print(X_train[150:160])\r\n\r\n    # Lts do data normalization\r\n    mean = np.mean(X_train, axis=0)\r\n    std = np.std(X_train, axis=0)\r\n\r\n    X_train = (X_train - mean)/std\r\n    X_test = (X_test - mean)/std\r\n\r\n    # Check the dataset now\r\n    X_train[150:160]\r\n\r\n    # Lets few preparation steps to get it into the correct format for Keras\r\n    X_train = np.array(X_train)\r\n    y_train = np.array(y_train)\r\n    X_test = np.array(X_test)\r\n    y_test = np.array(y_test)\r\n\r\n    # one shot encode the target\r\n    lb = LabelEncoder()\r\n    y_train = np_utils.to_categorical(lb.fit_transform(y_train))\r\n    y_test = np_utils.to_categorical(lb.fit_transform(y_test))\r\n\r\n    print(X_train.shape)\r\n    print(lb.classes_)\r\n    # print(y_train[0:10])\r\n    # print(y_test[0:10])\r\n\r\n    # Pickel the lb object for future use\r\n    filename = 'labels'\r\n    outfile = open(filename, 'wb')\r\n    pickle.dump(lb, outfile)\r\n    outfile.close()\r\n\r\n    X_train = np.expand_dims(X_train, axis=2)\r\n    X_test = np.expand_dims(X_test, axis=2)\r\n    X_train.shape\r\n\r\n    return X_train, X_test, y_train, y_test, lb\r\ndef CNN_1D_Create(X_train, Y_train):\r\n    # New model\r\n    class_count = len(Y_train[0])\r\n    \r\n    model = Sequential()\r\n    # X_train.shape[1] = No. of Columns\r\n    model.add(Conv1D(256, 8, padding='same',\r\n              input_shape=(X_train.shape[1], 1)))\r\n    model.add(Activation('relu'))\r\n    model.add(Conv1D(256, 8, padding='same'))\r\n    model.add(BatchNormalization())\r\n    model.add(Activation('relu'))\r\n    model.add(Dropout(0.25))\r\n    model.add(MaxPooling1D(pool_size=(8)))\r\n    model.add(Conv1D(128, 8, padding='same'))\r\n    model.add(Activation('relu'))\r\n    model.add(Conv1D(128, 8, padding='same'))\r\n    model.add(Activation('relu'))\r\n    model.add(Conv1D(128, 8, padding='same'))\r\n    model.add(Activation('relu'))\r\n    model.add(Conv1D(128, 8, padding='same'))\r\n    model.add(BatchNormalization())\r\n    model.add(Activation('relu'))\r\n    model.add(Dropout(0.25))\r\n    model.add(MaxPooling1D(pool_size=(8)))\r\n    model.add(Conv1D(64, 8, padding='same'))\r\n    model.add(Activation('relu'))\r\n    model.add(Conv1D(64, 8, padding='same'))\r\n    model.add(Activation('relu'))\r\n    model.add(Flatten())\r\n    model.add(Dense(class_count))  # Target class number\r\n    model.add(Activation('softmax'))\r\n    # opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\r\n    # opt = keras.optimizers.Adam(lr=0.0001)\r\n    opt = keras.optimizers.legacy.RMSprop(lr=0.00001, decay=1e-6)\r\n    model.summary()\r\n    return model, opt\r\ndef CNN_1D_Train(model, opt, X_train, y_train, X_test, y_test):\r\n    model.compile(loss='categorical_crossentropy',\r\n                  optimizer=opt, metrics=['accuracy'])\r\n    model_history = model.fit(\r\n        X_train, y_train, batch_size=64, epochs=20, validation_data=(X_test, y_test))\r\n    # NOTE: I degressesed epeoch count for initial testing\r\n    plt.plot(model_history.history['loss'])\r\n    plt.plot(model_history.history['val_loss'])\r\n    plt.title('model loss')\r\n    plt.ylabel('loss')\r\n    plt.xlabel('epoch')\r\n    plt.legend(['train', 'test'], loc='upper left')\r\n    plt.show()\r\n\r\n    return model\r\ndef CNN_Save(model, model_name):\r\n    # Save model and weights\r\n    save_dir = os.path.join(os.getcwd(), 'saved_models')\r\n\r\n    if not os.path.isdir(save_dir):\r\n        os.makedirs(save_dir)\r\n    model_path = os.path.join(save_dir, model_name)\r\n    model.save(model_path)\r\n    print('Save model and weights at %s ' % model_path)\r\n\r\n    # Save the model to disk\r\n    model_json = model.to_json()\r\n    with open(\"model_json.json\", \"w\") as json_file:\r\n        json_file.write(model_json)\r\ndef CNN_1D_Load(model_name, X_test, y_test):\r\n    # loading json and model architecture\r\n    json_file = open('model_json.json', 'r')\r\n    loaded_model_json = json_file.read()\r\n    json_file.close()\r\n    loaded_model = model_from_json(loaded_model_json)\r\n\r\n    # load weights into new model\r\n    loaded_model.load_weights(\"saved_models/\" + model_name)\r\n    print(\"Loaded model from disk\\n\")\r\n\r\n    # Keras optimiser\r\n    opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\r\n    loaded_model.compile(loss='categorical_crossentropy',\r\n                         optimizer=opt, metrics=['accuracy'])\r\n    score = loaded_model.evaluate(X_test, y_test, verbose=0)\r\n    print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\r\n\r\n    return loaded_model\r\ndef CNN_1D_Predictions(model, lb, X_test, y_test):\r\n    preds = model.predict(X_test, batch_size=16, verbose=1)\r\n    preds = preds.argmax(axis=1)\r\n    preds\r\n    # predictions\r\n    preds = preds.astype(int).flatten()\r\n    preds = (lb.inverse_transform((preds)))\r\n    preds = pd.DataFrame({'predictedvalues': preds})\r\n\r\n    # Actual labels\r\n    actual = y_test.argmax(axis=1)\r\n    actual = actual.astype(int).flatten()\r\n    actual = (lb.inverse_transform((actual)))\r\n    actual = pd.DataFrame({'actualvalues': actual})\r\n\r\n    # Lets combined both of them into a single dataframe\r\n    finaldf = actual.join(preds)\r\n    print(finaldf[170:180])\r\n\r\n    # Write out the predictions to disk\r\n    finaldf.to_csv('Predictions.csv', index=False)\r\n    finaldf.groupby('predictedvalues').count()\r\n\r\n    # Get the predictions file\r\n    finaldf = pd.read_csv(\"Predictions.csv\")\r\n    classes = finaldf.actualvalues.unique()\r\n    classes.sort()\r\n\r\n    # Confusion matrix\r\n    c = confusion_matrix(finaldf.actualvalues, finaldf.predictedvalues)\r\n    print(accuracy_score(finaldf.actualvalues, finaldf.predictedvalues))\r\n    # print_confusion_matrix(c, class_names=classes)\r\n\r\n    # Classification report\r\n    classes = finaldf.actualvalues.unique()\r\n    classes.sort()\r\n    print(classification_report(finaldf.actualvalues,\r\n          finaldf.predictedvalues, target_names=classes))\r\n\r\n    modidf = finaldf\r\n    # modidf['actualvalues'] = finaldf.actualvalues.replace({'female_angry': 'female', 'female_disgust': 'female', 'female_fear': 'female', 'female_happy': 'female', 'female_sad': 'female', 'female_surprise': 'female', 'female_neutral': 'female', 'male_angry': 'male', 'male_fear': 'male', 'male_happy': 'male', 'male_sad': 'male', 'male_surprise': 'male', 'male_neutral': 'male', 'male_disgust': 'male'\r\n    #                                                        })\r\n\r\n    # modidf['predictedvalues'] = finaldf.predictedvalues.replace({'female_angry': 'female', 'female_disgust': 'female', 'female_fear': 'female', 'female_happy': 'female', 'female_sad': 'female', 'female_surprise': 'female', 'female_neutral': 'female', 'male_angry': 'male', 'male_fear': 'male', 'male_happy': 'male', 'male_sad': 'male', 'male_surprise': 'male', 'male_neutral': 'male', 'male_disgust': 'male'\r\n    #                                                              })\r\n\r\n    # classes = modidf.actualvalues.unique()\r\n    # classes.sort()\r\n\r\n    # # Confusion matrix\r\n    # c = confusion_matrix(modidf.actualvalues, modidf.predictedvalues)\r\n    # print(accuracy_score(modidf.actualvalues, modidf.predictedvalues))\r\n    # print_confusion_matrix(c, class_names=classes)\r\n\r\n    # Classification report\r\n    classes = modidf.actualvalues.unique()\r\n    classes.sort()\r\n    print(classification_report(modidf.actualvalues,\r\n          modidf.predictedvalues, target_names=classes))\r\n\r\n    modidf = pd.read_csv(\"Predictions.csv\")\r\n    modidf['actualvalues'] = modidf.actualvalues.replace({'female_angry': 'angry', 'female_disgust': 'disgust', 'female_fear': 'fear', 'female_happy': 'happy', 'female_sad': 'sad', 'female_surprise': 'surprise', 'female_neutral': 'neutral', 'male_angry': 'angry', 'male_fear': 'fear', 'male_happy': 'happy', 'male_sad': 'sad', 'male_surprise': 'surprise', 'male_neutral': 'neutral', 'male_disgust': 'disgust'\r\n                                                          })\r\n\r\n    modidf['predictedvalues'] = modidf.predictedvalues.replace({'female_angry': 'angry', 'female_disgust': 'disgust', 'female_fear': 'fear', 'female_happy': 'happy', 'female_sad': 'sad', 'female_surprise': 'surprise', 'female_neutral': 'neutral', 'male_angry': 'angry', 'male_fear': 'fear', 'male_happy': 'happy', 'male_sad': 'sad', 'male_surprise': 'surprise', 'male_neutral': 'neutral', 'male_disgust': 'disgust'\r\n                                                                })\r\n\r\n    classes = modidf.actualvalues.unique()\r\n    classes.sort()\r\n\r\n    # Confusion matrix\r\n    c = confusion_matrix(modidf.actualvalues, modidf.predictedvalues)\r\n    print(accuracy_score(modidf.actualvalues, modidf.predictedvalues))\r\n    # print_confusion_matrix(c, class_names=classes)\r\n\r\n    # Classification report\r\n    classes = modidf.actualvalues.unique()\r\n    classes.sort()\r\n    print(classification_report(modidf.actualvalues,\r\n          modidf.predictedvalues, target_names=classes))\r\n\r\ndef print_confusion_matrix(confusion_matrix, class_names, figsize=(10, 7), fontsize=14):\r\n    # the confusion matrix heat map plot\r\n    # Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\r\n    df_cm = pd.DataFrame(\r\n        confusion_matrix, index=class_names, columns=class_names,\r\n    )\r\n    fig = plt.figure(figsize=figsize)\r\n    try:\r\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", ax=None) # Matplotlib not supported\r\n    except ValueError:\r\n        raise ValueError(\"Confusion matrix values must be integers.\")\r\n\r\n    heatmap.yaxis.set_ticklabels(\r\n        heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\r\n    heatmap.xaxis.set_ticklabels(\r\n        heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\r\n    plt.ylabel('True label')\r\n    plt.xlabel('Predicted label')\r\n    plt.show()\r\ndef gender(row):\r\n    # Gender recode funct\r\n    if row == 'female_disgust' or 'female_fear' or 'female_happy' or 'female_sad' or 'female_surprise' or 'female_neutral':\r\n        return 'female'\r\n    elif row == 'male_angry' or 'male_fear' or 'male_happy' or 'male_sad' or 'male_surprise' or 'male_neutral' or 'male_disgust':\r\n        return 'male'\r\n\r\n# _________________________________________________________________________________________________\r\ndef scale_minmax(X, min=0.0, max=1.0):\r\n    X_std = (X - X.min()) / (X.max() - X.min())\r\n    X_scaled = X_std * (max - min) + min\r\n    return X_scaled\r\ndef spectrogram_image(y, sr, out_dir, out_name, hop_length, n_mels):\r\n    # use log-melspectrogram\r\n    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, n_fft=hop_length*2, hop_length=hop_length)\r\n    # mels = librosa.feature.melspectrogram(y=y, sr=sr)\r\n    \r\n    if 1:\r\n        mels = np.log(mels + 1e-9) # add small number to avoid log(0)\r\n    else:  #testing !\r\n        mels = np.mean(mels, axis=0)\r\n        \r\n    # min-max scale to fit inside 8-bit range\r\n    img = scale_minmax(mels, 0, 255).astype(np.uint8)\r\n    img = np.flip(img, axis=0) # put low frequencies at the bottom in image\r\n    img = 255 - img            # invert. make black==more energy\r\n    \r\n    # save as PNG\r\n    if not os.path.exists(out_dir):\r\n        os.makedirs(out_dir)\r\n    \r\n    cv2.imwrite((out_dir + \"//\" + out_name), img)\r\ndef save_wav_to_png(df, DATA_SAMPLES_CNT, BASE_PATH, IMG_HEIGHT, IMG_WIDTH, use_Kfold = False):\r\n    \"\"\" \r\n    Saves spectograms data from sound files as png pictures\r\n    \"\"\"\r\n    print(\"Saving pictures to drive\")\r\n    for i in range(DATA_SAMPLES_CNT):\r\n        file_name = BASE_PATH  + \"//audio//\" + str(df[\"filename\"][i])\r\n        y, sr = librosa.load(file_name, res_type='kaiser_fast') \r\n        \r\n        img_name = 'out' + str(i+1) + \"_\" + str(df[\"target\"][i]) + '.png'\r\n        hop_length = 512           # number of samples per time-step in spectrogram\r\n        n_mels = IMG_HEIGHT        # number of bins in spectrogram. Height of image\r\n        time_steps = IMG_WIDTH - 1 # number of time-steps. Width of image (TODO FIX it add 1 px to width!!)\r\n        \r\n        y = librosa.util.utils.fix_length(y, sr * 2.5)\r\n        \r\n        start_sample = 0 # starting at beginning\r\n        length_samples = time_steps * hop_length\r\n        window = y[start_sample:start_sample+length_samples]\r\n        dir_name = \"mel_img\"\r\n        \r\n        spectrogram_image(y=window, sr=sr, out_dir=dir_name , out_name=img_name, hop_length=hop_length, n_mels=n_mels)\r\n    print(\"Done saving pictures!\")\r\n\r\ndef CNN_2D_ProcessData(ref):\r\n    # Note this takes a couple of minutes (~10 mins) as we're iterating over 4 datasets \r\n    df = pd.DataFrame(columns=['feature'])\r\n    # loop feature extraction over the entire dataset\r\n    counter=0\r\n    for index,path in enumerate(ref.path):\r\n        X_mel, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=44100,offset=0.5)\r\n        sample_rate = np.array(sample_rate)\r\n        \r\n        IMG_HEIGHT = 256    \r\n        IMG_WIDTH = 256\r\n        \r\n        img_name = 'out_nr' + str(counter+1) + '.png'\r\n        hop_length = 512           # number of samples per time-step in spectrogram\r\n        n_mels = IMG_HEIGHT        # number of bins in spectrogram. Height of image\r\n        time_steps = IMG_WIDTH - 1 # number of time-steps. Width of image (TODO FIX it add 1 px to width!!)\r\n            \r\n        X_mel = librosa.util.utils.fix_length(X_mel, size=110250) # 2.5 * sr\r\n            \r\n        start_sample = 0 # starting at beginning\r\n        length_samples = time_steps * hop_length\r\n        window = X_mel[start_sample:start_sample+length_samples]\r\n        dir_name = \"mel_img\"\r\n            \r\n        spectrogram_image(y=window, sr=sample_rate, out_dir=dir_name , out_name=img_name, hop_length=hop_length, n_mels=n_mels)\r\n        \r\n        counter=counter+1\r\n        if(counter % 100 == 0):\r\n            print(f\"Progress(Mel spectrogram): {counter}\", end=\"\\r\")\r\n    # Check a few records to make sure its processed successfully\r\n    print(len(df))\r\n    print(df.head(10))\r\n    return df\r\ndef CNN_2D_DisplayData(y_train, y_test):\r\n    # show some pics\r\n    pic_cnt = 0\r\n    path = \"mel_img\"\r\n\r\n    for filename in os.listdir(path):\r\n        if filename.endswith(\".png\"):\r\n            image_path = os.path.join(path, filename)\r\n            image = Image.open(image_path)\r\n            image.show()\r\n            print(image_path)\r\n            \r\n            pic_cnt += 1\r\n            if pic_cnt > 5:\r\n                break\r\n    \r\n    print(y_train.size)\r\n    print(y_train.shape)\r\n    print(y_train)\r\n    print(y_test.size)\r\n    print(y_test.shape)\r\n    print(y_test)\r\n    \r\n    png_count = 0\r\n    for filename in os.listdir(path):\r\n        if filename.endswith(\".png\"):\r\n            png_count = png_count + 1\r\n    print(png_count)\r\ndef CNN_2D_Label(df_all_DB):\r\n    lb = LabelEncoder()\r\n    Y_mell = np_utils.to_categorical(lb.fit_transform(df_all_DB.labels))\r\n    # y_test_mell = np_utils.to_categorical(lb.fit_transform(y_test))\r\n    print(Y_mell)\r\n    print(Y_mell[0])\r\n    print(Y_mell[1])\r\n    \r\n    # Invert the one-hot encoding\r\n    Y_mell_labels = np.argmax(Y_mell, axis=1)\r\n\r\n    # print(Y_mell_labels)\r\n    print(min(Y_mell_labels))\r\n    print(max(Y_mell_labels))\r\n    return Y_mell_labels\r\n   \r\ndef CNN_2D_LoadSpectograms(DATA_SAMPLES_CNT, IMG_HEIGHT, IMG_WIDTH):\r\n    print(\"Loading images from drive to RAM!\")\r\n    img_data_array = np.zeros((DATA_SAMPLES_CNT, IMG_HEIGHT, IMG_WIDTH))\r\n    \r\n    for i in range(0, DATA_SAMPLES_CNT):\r\n        image_path = \"mel_img//out_nr\" + str(i+1) + \".png\"\r\n        image= cv2.imread(image_path, cv2.COLOR_BGR2RGB) # TODO FIX: check color map\r\n        # image= cv2.imread(image_path)\r\n        if image is None:\r\n            print(\"Error, image was not found from: \" + image_path)\r\n            quit()\r\n        image = np.array(image)\r\n        image = image.astype('float32')\r\n        image /= 255\r\n        img_data_array[i] = image\r\n    print(\"Finish loading images from drive to RAM!\")\r\n    return img_data_array\r\ndef CNN_2D_LoadData(Y_mell_labels, IMG_HEIGHT, IMG_WIDTH):\r\n    samples_cnt = 12162\r\n    # samples_cnt = 8000\r\n    Y_mell_labels = Y_mell_labels[0:samples_cnt]\r\n\r\n    X_data_mell = CNN_2D_LoadSpectograms(samples_cnt, IMG_HEIGHT, IMG_WIDTH)\r\n    \r\n    # print(X_data_mell)\r\n    # print(X_data_mell[0])\r\n    \r\n    x_train_mell, x_test_mell, y_train_mell, y_test_mell = train_test_split(X_data_mell, Y_mell_labels, test_size=0.25, random_state=7)\r\n        \r\n    x_train_mell = x_train_mell.reshape(x_train_mell.shape[0], IMG_HEIGHT, IMG_WIDTH, 1)\r\n    x_test_mell = x_test_mell.reshape(x_test_mell.shape[0], IMG_HEIGHT, IMG_WIDTH, 1)\r\n    \r\n    return x_train_mell, x_test_mell, y_train_mell, y_test_mell\r\ndef CNN_2D_Create(img_h, img_w, class_cnt):\r\n    # Initialize model\r\n    model = Sequential()\r\n    # Layer 1\r\n    model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape = (img_h, img_w, 1), padding='same'))\r\n    model.add(MaxPooling2D((2, 2)))\r\n    # Layer 2\r\n    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same' ))\r\n    model.add(MaxPooling2D((2, 2)))\r\n    # Layer 3\r\n    model.add(Dense(64, activation = \"relu\"))\r\n    model.add(Dropout(0.2))\r\n    # Layer 4\r\n    model.add(Dense(64, activation = \"relu\"))\r\n    model.add(Dropout(0.5))\r\n    # Layer 5\r\n    model.add(Flatten())\r\n    model.add(Dense(class_cnt, activation = \"softmax\"))\r\n    \r\n    model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\r\n    model.summary()\r\n    return model\r\ndef CNN_2D_FitModel(model, x_train_mell, x_test_mell, y_train_mell, y_test_mell):\r\n    y_train_mell = to_categorical(y_train_mell)\r\n    y_test_mell = to_categorical(y_test_mell)\r\n    \r\n    earlystopper = callbacks.EarlyStopping(patience=10, verbose=1, monitor='val_accuracy')\r\n    checkpointer = callbacks.ModelCheckpoint('saved_models\\\\2D_CNN_checkpoint.h5', verbose=1, save_best_only=True)\r\n        \r\n    hist = model.fit(x_train_mell, y_train_mell, batch_size=32, epochs=20, verbose=1, validation_data=(x_test_mell, y_test_mell), callbacks = [earlystopper, checkpointer])\r\n    #     draw_model_results(hist)\r\n    return model\r\n\r\ndef ViT_Create(img_h, img_w, class_cnt):\r\n    learning_rate = 1e-4\r\n    batch_size = 64\r\n    num_epochs = 10\r\n    image_size = 224\r\n    num_classes = 120\r\n    num_steps = 1.0\r\n    \r\n    inputs = tf.keras.layers.Input(shape=(img_h, img_w, 1))\r\n\r\n    vit = ViTTiny16(\r\n        include_rescaling=False,\r\n        include_top=False,\r\n        name=\"ViTTiny32\",\r\n        weights=\"imagenet\",\r\n        input_tensor=inputs,\r\n        pooling=\"token_pooling\",\r\n        activation=tf.keras.activations.gelu,\r\n    )\r\n    vit.trainable = True\r\n    outputs = tf.keras.layers.Dense(class_cnt, activation=\"softmax\")(vit.output)\r\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n    model.summary()\r\n    \r\n    decay_steps = num_epochs * 10\r\n    cosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(\r\n        learning_rate, decay_steps, alpha=0.1)\r\n    \r\n    model.compile(\r\n    optimizer=tf.keras.optimizers.Adam(learning_rate=cosine_decay_scheduler),\r\n    loss=tf.keras.losses.CategoricalCrossentropy(),\r\n    metrics=[\"accuracy\"],)\r\n    \r\n    return model\r\ndef ViT_FitModel(model, x_train_mell, x_test_mell, y_train_mell, y_test_mell):\r\n    earlystopper = callbacks.EarlyStopping(patience=10, verbose=1, monitor='val_accuracy')\r\n    checkpointer = callbacks.ModelCheckpoint('saved_models\\\\ViT_checkpoint.h5', verbose=1, save_best_only=True)\r\n    \r\n    hist = model.fit(x_train_mell, y_train_mell, batch_size=32, epochs=20, verbose=1, validation_data=(x_test_mell, y_test_mell), callbacks = [earlystopper, checkpointer])\r\n    return model\r\n\r\n\r\ndef main():\r\n    # Read all data\r\n    if (GLB_READ_DATA == True):\r\n        SAVEE_df = ReadData_SAVEE()\r\n        RAVDESS_df = ReadData_RAVDESS()\r\n        TESS_df = ReadData_TESS()\r\n        CREMA_df = ReadData_CREMA()\r\n        DataframesToCsv(SAVEE_df, RAVDESS_df, TESS_df, CREMA_df)\r\n        MFCC_Example()\r\n        # Delte specific datasets dataframes to save data\r\n        del SAVEE_df\r\n        del RAVDESS_df\r\n        del TESS_df\r\n        del CREMA_df\r\n\r\n    # Read processed data\r\n    ref = ReadData_Path_CSV()\r\n    if not os.path.isfile(MFCC_PATH_CSV):\r\n        df_all_DB = DataframeAddMFCC(ref)\r\n    else:\r\n        df_all_DB = pd.read_csv(MFCC_PATH_CSV)\r\n    X_train, X_test, y_train, y_test, lb = PrepareData(df_all_DB)\r\n\r\n    # Create 1D CNN\r\n    if GLB_MODE == 1:\r\n        CNN_1D, CNN_1D_opt = CNN_1D_Create(X_train, y_train)\r\n        CNN_1D = CNN_1D_Train(CNN_1D, CNN_1D_opt, X_train,\r\n                              y_train, X_test, y_test)\r\n        CNN_Save(CNN_1D, 'CNN1D_1.h5')\r\n\r\n    # Load 1D CNN\r\n    if GLB_MODE == 2:\r\n        CNN_1D = CNN_1D_Load('CNN1D_1.h5', X_test, y_test)\r\n        CNN_1D_Predictions(CNN_1D, lb, X_test, y_test)\r\n\r\n    # Create 2D CNN\r\n    if GLB_MODE == 3:\r\n        IMG_HEIGHT = 256    \r\n        IMG_WIDTH = 216\r\n        if not os.path.isdir('mel_img'):\r\n            df2d = CNN_2D_ProcessData(ref)\r\n        if GLB_DISPLAY_DATA:\r\n            CNN_2D_DisplayData(y_train, y_test)\r\n        labels = CNN_2D_Label(df_all_DB)\r\n        class_count = len(np.unique(labels))\r\n        x_train_mell, x_test_mell, y_train_mell, y_test_mell = CNN_2D_LoadData(labels, IMG_HEIGHT, IMG_WIDTH)\r\n        CNN_2D = CNN_2D_Create(IMG_HEIGHT, IMG_WIDTH, class_count)\r\n        CNN_2D_FitModel(CNN_2D, x_train_mell, x_test_mell, y_train_mell, y_test_mell)\r\n        CNN_Save(CNN_2D, 'CNN2D_1.h5')\r\n        \r\n    # Load 2D CNN\r\n    if GLB_MODE == 4:\r\n        IMG_HEIGHT = 256    \r\n        IMG_WIDTH = 216\r\n        labels = CNN_2D_Label(df_all_DB)\r\n        class_count = len(np.unique(labels))\r\n        x_train_mell, x_test_mell, y_train_mell, y_test_mell = CNN_2D_LoadData(labels, IMG_HEIGHT, IMG_WIDTH)\r\n        y_train_mell = to_categorical(y_train_mell)\r\n        y_test_mell = to_categorical(y_test_mell)\r\n        CNN_2D = CNN_1D_Load('CNN2D_1.h5', x_test_mell, y_test_mell)\r\n        \r\n    # Create ViT\r\n    if GLB_MODE == 5:\r\n        IMG_HEIGHT = 256    \r\n        IMG_WIDTH = 216\r\n        if not os.path.isdir('mel_img'):\r\n            df2d = CNN_2D_ProcessData(ref)\r\n        if GLB_DISPLAY_DATA:\r\n            CNN_2D_DisplayData(y_train, y_test)\r\n        labels = CNN_2D_Label(df_all_DB)\r\n        class_count = len(np.unique(labels))\r\n        x_train_mell, x_test_mell, y_train_mell, y_test_mell = CNN_2D_LoadData(labels, IMG_HEIGHT, IMG_WIDTH)\r\n        VIT = ViT_Create(IMG_HEIGHT, IMG_WIDTH, class_count)\r\n        CNN_2D_FitModel(VIT, x_train_mell, x_test_mell, y_train_mell, y_test_mell)\r\n        CNN_Save(VIT, 'VIT_1.h5')\r\n    \r\n    print(\"FINISHED!\\n\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()","metadata":{"_uuid":"1590a68a-e33b-40fb-a783-6ab5fda673a8","_cell_guid":"56dc84ef-7353-4d48-9334-4e638a92dc4c","collapsed":false,"jupyter":{"outputs_hidden":false},"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}